# SASRec + CE / CCE

Этот проект реализует обучение модели **SASRec** для рекомендательных систем.
Произведено сравнение **стандартной CrossEntropy (CE)** и **Сut CrossEntropy (CCE)** в реализации Apple: 
[статья](https://arxiv.org/pdf/2411.09009), [репозиторий](https://github.com/apple/ml-cross-entropy).

Сравнение проводилось с точки зрения:
- качества рекомендаций,
- среднего времени обучения по всем эпохам,
- максимального потребления GPU памяти.

---

## Основные компоненты

- **SASRec** — self-attention последовательная модель
- **Лоссы**:
  - `CE` — стандартная кросс-энтропия
  - `CCE` — эффективная реализация
- **Метрики**:
  - `HitRate@k` — попадание целевого item’а в топ-k
  - `NDCG@k` — качество по позиции
  - `Coverage@k` — разнообразие
  - `Surprisal@k` — неожиданность
- **Датасеты**:
  - MovieLens-20m
  - Amazon Beauty
 

## Статистика датасетов
Данные о размере и параметрах предварительной фильтрации для используемых датасетов:

| Dataset   | # Users | # Items | BS  | SL | ES | Min User| Min Item |
|-----------|---------|---------|-----|----|----|---------|----------|
| MovieLens | 138,493 | 20,729  | 256 | 50 | 64 |   3     |   3      |
| Beauty    | 729,576 | 207,649 | 256 | 50 | 64 |   3     |   3      |

Обозначения:

* N Users — количество уникальных пользователей
* N Items — количество уникальных объектов (фильмы, товары и т.д.)
* BS (Batch Size) — размер батча при обучении
* SL (Sequence Length) — длина последовательности (макс. число интеракций на пользователя)
* ES (Embedding Size) — размер эмбеддинга
* Min User — минимальное число интеракций на пользователя (фильтрация)
* Min Item — минимальное число интеракций на объект (фильтрация)

## Результаты

| Dataset   | Loss | HitRate@10 | NDCG@10  |  Coverage@10 |  Surprisal@10 |  Max Memory (GB) | Epoch (s) |
|-----------|------|------------|----------|--------------|---------------|------------------|-----------|
| MovieLens | CE   | 0.033814   | 0.015521 | 0.005934     | 0.094077      | 0.263            | 11        |
| MovieLens | CCE  | 0.030998   | 0.014186 | 0.001303     | 0.080424      | 0.205            | 12        |
| Beauty    | CE   | 0.009277   | 0.005239 | 0.010830     | 0.395284      | 1.085            | 105       |
| Beauty    | CCE  | 0.009655   | 0.005392 | 0.000130     | 0.389152      | 0.711            | 87        |


## Выводы

В ходе эксперимента проведено сравнение функций потерь Cross-Entropy (CE) и Cut Cross-Entropy (CCE) на датасетах MovieLens 20M и Beauty. Целью было выявление различий в производительности и ресурсной эффективности.

CCE, разработанная специально для обучения в условиях большого признакового пространства, показывает сопоставимое качество при меньшем потреблении памяти и ускоренном обучении. На датасете MovieLens (≈20K items) преимущества CCE выражены слабо: время обучения на эпоху не изменилось в пределах погрешности, а потребление памяти сократилось на ~20%. В то же время на более крупном датасете Beauty (≈207K items) уже наблюдается заметное преимущество: время на эпоху снижено на ~17%, а пиковое потребление памяти — на ~35%.

Таким образом, эффективность CCE проявляется ярче по мере роста размерности item-пространства.  Важно отметить, что гиперпараметры не подбирались, модели запускались с одинаковыми базовыми настройками, без оптимизации, поэтому полученные результаты нельзя считать финальными. В дальнейшем планируется валидация на ещё более масштабных датасетах, где ожидается существенный выигрыш, а также дообучение моделей с целью максимизации приведенных метрик.